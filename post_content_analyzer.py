#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Post Content Analyzer

nside_with_persona.csvì˜ post_contentë¥¼ ë¶„ì„í•˜ì—¬
ì¦ìƒ/ì§„ë£Œ/ì¹˜ë£Œ/ì¹´í…Œê³ ë¦¬ë¡œ êµ¬ì¡°í™”í•˜ê³  ì €ì¥í•˜ëŠ” ë„êµ¬

AI ëª¨ë¸(Gemini 1.5 Flash)ê³¼ í‚¤ì›Œë“œ ë§¤ì¹­ì„ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹ ì‚¬ìš©
"""

import json
import os
import re
from pathlib import Path
from typing import Dict, List, Optional
import pandas as pd
import google.generativeai as genai
from dotenv import load_dotenv


class PostContentAnalyzer:
    """
    post_contentë¥¼ AI ëª¨ë¸ë¡œ 1ì°¨ ë¶„ë¥˜ í›„, í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ê²€ì¦í•˜ëŠ” í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ê¸°
    """

    def __init__(self, category_csv_path: str = "test_data/category_data.csv"):
        self.category_csv_path = Path(category_csv_path)

        # Gemini ëª¨ë¸ ì´ˆê¸°í™”
        load_dotenv()
        genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
        self.model = genai.GenerativeModel('gemini-1.5-flash')

        # ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ KB êµ¬ì¶•
        self.category_kb = self._build_kb_from_csv()

    def _build_kb_from_csv(self) -> Dict[str, Dict[str, List[str]]]:
        """category_data.csvì—ì„œ ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ KB êµ¬ì¶• (euc-kr ì¸ì½”ë”© ì‚¬ìš©)"""
        kb: Dict[str, Dict[str, List[str]]] = {}
        if not self.category_csv_path.exists():
            print(f"âš ï¸ {self.category_csv_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return kb

        try:
            # euc-kr ì¸ì½”ë”©ìœ¼ë¡œ ì½ê¸°
            df = pd.read_csv(self.category_csv_path, encoding='euc-kr').fillna("")
            for col in ["ì¦ìƒ", "ì§„ë£Œ", "ì¹˜ë£Œ", "ì¹´í…Œê³ ë¦¬"]:
                if col not in df.columns:
                    df[col] = ""

            for _, row in df.iterrows():
                cat = self._clean_text(str(row.get("ì¹´í…Œê³ ë¦¬", "")))
                if not cat:
                    continue
                kb.setdefault(cat, {"symptoms": [], "procedures": [], "treatments": []})
                kb[cat]["symptoms"] += self._extract_keywords(self._clean_text(row.get("ì¦ìƒ", "")))
                kb[cat]["procedures"] += self._extract_keywords(self._clean_text(row.get("ì§„ë£Œ", "")))
                kb[cat]["treatments"] += self._extract_keywords(self._clean_text(row.get("ì¹˜ë£Œ", "")))

            # ì¤‘ë³µ ì œê±°
            for cat, d in kb.items():
                for f in ("symptoms", "procedures", "treatments"):
                    d[f] = self._dedup_keep_order(d[f])

            print(f"âœ… {len(kb)}ê°œ ì¹´í…Œê³ ë¦¬ì˜ í‚¤ì›Œë“œ KB êµ¬ì¶• ì™„ë£Œ")
            return kb

        except Exception as e:
            print(f"âŒ KB êµ¬ì¶• ì‹¤íŒ¨: {e}")
            return {}

    @staticmethod
    def _clean_text(s: str) -> str:
        """í…ìŠ¤íŠ¸ ì •ë¦¬"""
        if not isinstance(s, str):
            return ""
        s = s.strip()
        s = re.sub(r"\s+", " ", s)
        return s

    @staticmethod
    def _extract_keywords(text: str, max_tokens: int = 100) -> set:
        """í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        if not isinstance(text, str):
            return set()
        # í•œê¸€, ì˜ë¬¸, ìˆ«ìë§Œ ë‚¨ê¸°ê³  ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬
        text = re.sub(r"[^ê°€-í£A-Za-z0-9\s]", " ", text)
        toks = [t for t in text.split() if len(t) >= 2]
        return set(toks[:max_tokens])

    @staticmethod
    def _dedup_keep_order(items: List[str]) -> List[str]:
        """ì¤‘ë³µ ì œê±°í•˜ë©´ì„œ ìˆœì„œ ìœ ì§€"""
        seen, out = set(), []
        for x in items or []:
            x = str(x).strip()
            if x and x not in seen:
                seen.add(x)
                out.append(x)
        return out

    def analyze_post_content(self, post_content: str) -> Dict[str, str]:
        """
        post_contentë¥¼ AI ëª¨ë¸ë¡œ 1ì°¨ ë¶„ë¥˜ í›„, í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ê²€ì¦

        Returns:
            {
                "symptoms": "ì¶”ì¶œëœ ì¦ìƒ",
                "procedures": "ì¶”ì¶œëœ ì§„ë£Œ",
                "treatments": "ì¶”ì¶œëœ ì¹˜ë£Œ",
                "category": "ì¶”ì¶œëœ ì¹´í…Œê³ ë¦¬",
                "confidence": "ì‹ ë¢°ë„ (0.0-1.0)",
                "verification_method": "ê²€ì¦ ë°©ë²•"
            }
        """
        if not post_content or len(post_content.strip()) < 50:
            return {
                "symptoms": "", "procedures": "", "treatments": "",
                "category": "", "confidence": 0.0, "verification_method": "content_too_short"
            }

        # 1ë‹¨ê³„: AI ëª¨ë¸ë¡œ 1ì°¨ ë¶„ë¥˜
        ai_result = self._ai_classify_post_content(post_content)

        # 2ë‹¨ê³„: í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ê²€ì¦
        verified_result = self._verify_with_keywords(post_content, ai_result)

        return verified_result

    def _ai_classify_post_content(self, post_content: str) -> Dict[str, str]:
        """AI ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ post_contentë¥¼ ì¦ìƒ/ì§„ë£Œ/ì¹˜ë£Œ/ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜"""
        try:
            prompt = f"""
ë‹¤ìŒ ì¹˜ê³¼ ê´€ë ¨ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì¦ìƒ, ì§„ë£Œ, ì¹˜ë£Œ, ì¹´í…Œê³ ë¦¬ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

í¬ìŠ¤íŠ¸ ë‚´ìš©:
{post_content[:2000]}...

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "symptoms": "í™˜ìê°€ ê²ªê³  ìˆëŠ” ì¹˜ì•„ ë¬¸ì œë‚˜ ì¦ìƒ",
    "procedures": "ì˜ì‚¬ê°€ ì§„í–‰í•œ ì§„ë£Œ ê³¼ì •ì´ë‚˜ ê³„íš",
    "treatments": "ì‹¤ì œ ì‹œìˆ ì´ë‚˜ ì¹˜ë£Œ ë‚´ìš©",
    "category": "ì¹˜ë£Œ ë¶„ë¥˜ (ì„í”Œë€íŠ¸, ì‹¬ë¯¸ìˆ˜ë³µ, ì‹ ê²½ì¹˜ë£Œ, ì¶©ì¹˜ì¹˜ë£Œ, í¬ë¼ìš´ë³´ì² , ë°œì¹˜, ë³´ì² , ë¯¸ë°± ì¤‘ í•˜ë‚˜)"
}}

ì£¼ì˜ì‚¬í•­:
- ì¦ìƒì€ í™˜ìê°€ ëŠë¼ëŠ” ë¶ˆí¸í•¨ì´ë‚˜ ë¬¸ì œì 
- ì§„ë£ŒëŠ” ì˜ì‚¬ì˜ ì§„ë‹¨ì´ë‚˜ ì¹˜ë£Œ ê³„íš
- ì¹˜ë£ŒëŠ” ì‹¤ì œ ì‹œìˆ  ë‚´ìš©
- ì¹´í…Œê³ ë¦¬ëŠ” ìœ„ 8ê°œ ì¤‘ ê°€ì¥ ì í•©í•œ í•˜ë‚˜ë§Œ ì„ íƒ
- ê° í•­ëª©ì€ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì‘ì„±
"""

            response = self.model.generate_content(prompt)
            result_text = response.text.strip()

            # JSON ì¶”ì¶œ ì‹œë„
            try:
                # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
                if "{" in result_text and "}" in result_text:
                    start = result_text.find("{")
                    end = result_text.rfind("}") + 1
                    json_str = result_text[start:end]
                    result = json.loads(json_str)
                else:
                    raise ValueError("JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤")

                # í•„ìˆ˜ í•„ë“œ í™•ì¸
                required_fields = ["symptoms", "procedures", "treatments", "category"]
                for field in required_fields:
                    if field not in result:
                        result[field] = ""

                return result

            except (json.JSONDecodeError, ValueError) as e:
                print(f"AI ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
                # ê¸°ë³¸ê°’ ë°˜í™˜
                return {
                    "symptoms": "", "procedures": "", "treatments": "", "category": ""
                }

        except Exception as e:
            print(f"AI ë¶„ë¥˜ ì‹¤íŒ¨: {e}")
            return {
                "symptoms": "", "procedures": "", "treatments": "", "category": ""
            }

    def _verify_with_keywords(self, post_content: str, ai_result: Dict[str, str]) -> Dict[str, str]:
        """í‚¤ì›Œë“œ ë§¤ì¹­ì„ í†µí•´ AI ê²°ê³¼ë¥¼ ê²€ì¦í•˜ê³  ë³´ì •"""
        # post_contentì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        content_keywords = self._extract_keywords(post_content, max_tokens=100)

        # AI ê²°ê³¼ ê²€ì¦
        verified = ai_result.copy()
        confidence = 0.0
        verification_method = "ai_only"

        # ì¹´í…Œê³ ë¦¬ ê²€ì¦
        if ai_result.get("category"):
            category = ai_result["category"]
            if category in self.category_kb:
                # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ í‚¤ì›Œë“œì™€ ë§¤ì¹­ í™•ì¸
                cat_keywords = set()
                for field in ["symptoms", "procedures", "treatments"]:
                    cat_keywords.update(self.category_kb[category][field])

                # í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
                matches = content_keywords.intersection(cat_keywords)
                if matches:
                    confidence += 0.3
                    verification_method = "ai_keyword_verified"

                # ì¦ìƒ/ì§„ë£Œ/ì¹˜ë£Œ í•„ë“œ ê²€ì¦ ë° ë³´ì •
                for field, field_name in [("symptoms", "symptoms"), ("procedures", "procedures"), ("treatments", "treatments")]:
                    if not ai_result.get(field):
                        # AIê°€ ì¶”ì¶œí•˜ì§€ ëª»í•œ ê²½ìš°, í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ë³´ì •
                        field_keywords = self.category_kb[category][field]
                        matched_keywords = [kw for kw in field_keywords if kw in post_content]
                        if matched_keywords:
                            verified[field] = ", ".join(matched_keywords[:3])  # ìƒìœ„ 3ê°œë§Œ
                            confidence += 0.1
                            verification_method = "ai_keyword_corrected"

        # ì¹´í…Œê³ ë¦¬ê°€ ì—†ê±°ë‚˜ ì˜ëª»ëœ ê²½ìš°, í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ì¬ë¶„ë¥˜
        if not ai_result.get("category") or ai_result["category"] not in self.category_kb:
            # í‚¤ì›Œë“œ ê¸°ë°˜ ì¹´í…Œê³ ë¦¬ ìŠ¤ì½”ì–´ë§
            scores = self._score_categories_by_keywords(content_keywords)
            if scores:
                best_category = max(scores, key=scores.get)
                verified["category"] = best_category
                confidence += 0.2
                verification_method = "keyword_based_fallback"

        # ìµœì¢… ì‹ ë¢°ë„ ê³„ì‚°
        confidence = min(1.0, confidence + 0.4)  # ê¸°ë³¸ 0.4 + ê²€ì¦ ì ìˆ˜

        verified["confidence"] = round(confidence, 2)
        verified["verification_method"] = verification_method

        return verified

    def _score_categories_by_keywords(self, content_keywords: set) -> Dict[str, float]:
        """í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ ì ìˆ˜ ê³„ì‚°"""
        scores = {}
        for category, kb_data in self.category_kb.items():
            total_matches = 0
            total_keywords = 0

            for field in ["symptoms", "procedures", "treatments"]:
                field_keywords = set(kb_data[field])
                matches = content_keywords.intersection(field_keywords)
                total_matches += len(matches)
                total_keywords += len(field_keywords)

            if total_keywords > 0:
                scores[category] = total_matches / total_keywords

        return scores

    def batch_analyze_posts(self, posts_data: List[Dict]) -> List[Dict]:
        """ì—¬ëŸ¬ post_contentë¥¼ ì¼ê´„ ë¶„ì„"""
        results = []
        total = len(posts_data)

        for i, post in enumerate(posts_data):
            print(f"ë¶„ì„ ì¤‘... ({i+1}/{total})")
            post_content = post.get("post_content", "")
            if post_content:
                analysis = self.analyze_post_content(post_content)
                # ì›ë³¸ ë°ì´í„°ì— ë¶„ì„ ê²°ê³¼ ì¶”ê°€
                post.update({
                    "analyzed_symptoms": analysis["symptoms"],
                    "analyzed_procedures": analysis["procedures"],
                    "analyzed_treatments": analysis["treatments"],
                    "analyzed_category": analysis["category"],
                    "analysis_confidence": analysis["confidence"],
                    "verification_method": analysis["verification_method"]
                })
            results.append(post)

        return results

    def convert_json_to_csv(self, json_path: str = "test_data/nside_with_persona.json",
                           csv_path: str = "test_data/nside_with_persona.csv") -> bool:
        """
        nside_with_persona.json íŒŒì¼ì„ CSVë¡œ ë³€í™˜
        
        Args:
            json_path: JSON íŒŒì¼ ê²½ë¡œ
            csv_path: ë³€í™˜í•  CSV íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ë³€í™˜ ì„±ê³µ ì—¬ë¶€
        """
        print(f"ğŸ”„ {json_path}ë¥¼ {csv_path}ë¡œ ë³€í™˜ ì¤‘...")
        
        json_path = Path(json_path)
        if not json_path.exists():
            print(f"âŒ {json_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
            
        try:
            # JSON íŒŒì¼ ë¡œë“œ
            with open(json_path, "r", encoding="utf-8") as f:
                data = json.load(f)
                
            # ë°ì´í„° êµ¬ì¡° í™•ì¸ ë° ë³€í™˜
            if isinstance(data, dict):
                # ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                records = []
                for key, value in data.items():
                    if isinstance(value, dict):
                        record = {"id": key, **value}
                        records.append(record)
                    else:
                        records.append({"id": key, "value": value})
                data = records
            elif isinstance(data, list):
                # ì´ë¯¸ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°
                records = data
            else:
                print(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°ì´í„° í˜•ì‹: {type(data)}")
                return False
                
            # DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ CSVë¡œ ì €ì¥
            df = pd.DataFrame(records)
            
            # CSV íŒŒì¼ ì €ì¥ (utf-8 ì¸ì½”ë”© ì‚¬ìš©)
            csv_path = Path(csv_path)
            csv_path.parent.mkdir(parents=True, exist_ok=True)
            df.to_csv(csv_path, encoding='utf-8', index=False)
            
            print(f"âœ… ë³€í™˜ ì™„ë£Œ! {len(records)}ê°œ í•­ëª©ì´ {csv_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return True
            
        except Exception as e:
            print(f"âŒ JSON to CSV ë³€í™˜ ì‹¤íŒ¨: {e}")
            return False

    def analyze_nside_file(self, input_path: str = "test_data/nside_with_persona.csv",
                       output_path: str = "test_data/nside_analyzed.csv") -> None:
        """
        nside_with_persona.csv íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ post_content ë¶„ì„ í›„ ì €ì¥

        Args:
            input_path: ì…ë ¥ CSV íŒŒì¼ ê²½ë¡œ
            output_path: ë¶„ì„ ê²°ê³¼ ì €ì¥ CSV ê²½ë¡œ
        """
        print("ğŸ” nside_with_persona.csv ë¶„ì„ ì‹œì‘...")

        # íŒŒì¼ ë¡œë“œ
        input_path = Path(input_path)
        if not input_path.exists():
            print(f"âŒ {input_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("   JSON íŒŒì¼ì„ CSVë¡œ ë³€í™˜í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ", end="")
            
            # ìë™ìœ¼ë¡œ JSONì„ CSVë¡œ ë³€í™˜ ì‹œë„
            json_path = input_path.with_suffix('.json')
            if json_path.exists():
                print(f"\nğŸ”„ {json_path}ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤. CSVë¡œ ë³€í™˜ì„ ì‹œë„í•©ë‹ˆë‹¤...")
                if self.convert_json_to_csv(str(json_path), str(input_path)):
                    print("âœ… ë³€í™˜ ì™„ë£Œ! ì´ì œ ë¶„ì„ì„ ì§„í–‰í•©ë‹ˆë‹¤.")
                else:
                    print("âŒ ë³€í™˜ ì‹¤íŒ¨. ìˆ˜ë™ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.")
                    return
            else:
                print("   CSV íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
                return

        try:
            # CSV íŒŒì¼ì„ euc-kr ì¸ì½”ë”©ìœ¼ë¡œ ì½ê¸°
            df = pd.read_csv(input_path, encoding='euc-kr')
            data = df.to_dict(orient='records')
        except Exception as e:
            print(f"âŒ CSV íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("   íŒŒì¼ì´ CSV í˜•ì‹ì´ê³  euc-kr ì¸ì½”ë”©ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return

        print(f"ğŸ“Š ì´ {len(data)}ê°œì˜ í•­ëª©ì„ ë¶„ì„í•©ë‹ˆë‹¤...")

        # post_contentê°€ ìˆëŠ” í•­ëª©ë§Œ í•„í„°ë§
        posts_to_analyze = []
        for i, row in enumerate(data):
            if isinstance(row, dict) and row.get("post_content"):
                posts_to_analyze.append({"index": i, **row})

        print(f"ğŸ“ ë¶„ì„í•  í¬ìŠ¤íŠ¸: {len(posts_to_analyze)}ê°œ")

        if not posts_to_analyze:
            print("âš ï¸ ë¶„ì„í•  post_contentê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ì¼ê´„ ë¶„ì„ ì‹¤í–‰
        analyzed_posts = self.batch_analyze_posts(posts_to_analyze)

        # ê²°ê³¼ë¥¼ ì›ë³¸ ë°ì´í„°ì— í†µí•©
        for analyzed_post in analyzed_posts:
            index = analyzed_post.pop("index")  # ì„ì‹œë¡œ ì¶”ê°€í–ˆë˜ index ì œê±°
            data[index].update(analyzed_post)

        # ë¶„ì„ëœ ë°ì´í„°ë¥¼ CSVë¡œ ì €ì¥
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        # DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
        result_df = pd.DataFrame(data)
        result_df.to_csv(output_path, encoding='euc-kr', index=False)

        print(f"âœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ê°€ {output_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

        # ë¶„ì„ í†µê³„ ì¶œë ¥
        self._print_analysis_stats(analyzed_posts)

    def _print_analysis_stats(self, analyzed_posts: List[Dict]) -> None:
        """ë¶„ì„ ê²°ê³¼ í†µê³„ ì¶œë ¥"""
        print("\nğŸ“Š ë¶„ì„ ê²°ê³¼ í†µê³„:")
        print("-" * 50)

        # ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬
        categories = {}
        confidence_ranges = {"0.0-0.5": 0, "0.5-0.7": 0, "0.7-0.9": 0, "0.9-1.0": 0}
        verification_methods = {}

        for post in analyzed_posts:
            # ì¹´í…Œê³ ë¦¬ í†µê³„
            cat = post.get("analyzed_category", "ë¯¸ë¶„ë¥˜")
            categories[cat] = categories.get(cat, 0) + 1

            # ì‹ ë¢°ë„ í†µê³„
            conf = post.get("analysis_confidence", 0.0)
            if conf < 0.5:
                confidence_ranges["0.0-0.5"] += 1
            elif conf < 0.7:
                confidence_ranges["0.5-0.7"] += 1
            elif conf < 0.9:
                confidence_ranges["0.7-0.9"] += 1
            else:
                confidence_ranges["0.9-1.0"] += 1

            # ê²€ì¦ ë°©ë²• í†µê³„
            method = post.get("verification_method", "unknown")
            verification_methods[method] = verification_methods.get(method, 0) + 1

        print("ğŸ·ï¸ ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬:")
        for cat, count in sorted(categories.items(), key=lambda x: x[1], reverse=True):
            print(f"  {cat}: {count}ê°œ")

        print("\nğŸ¯ ì‹ ë¢°ë„ ë¶„í¬:")
        for range_name, count in confidence_ranges.items():
            print(f"  {range_name}: {count}ê°œ")

        print("\nğŸ” ê²€ì¦ ë°©ë²• ë¶„í¬:")
        for method, count in sorted(verification_methods.items(), key=lambda x: x[1], reverse=True):
            print(f"  {method}: {count}ê°œ")

        print("-" * 50)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ” Post Content Analyzer ì‹œì‘")

    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    if not os.getenv("GEMINI_API_KEY"):
        print("âŒ GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   .env íŒŒì¼ì— GEMINI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        return

    # ë¶„ì„ê¸° ì´ˆê¸°í™”
    analyzer = PostContentAnalyzer()

    # nside íŒŒì¼ ë¶„ì„ ì‹¤í–‰ (CSVê°€ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ JSONì„ CSVë¡œ ë³€í™˜)
    analyzer.analyze_nside_file()


if __name__ == "__main__":
    main()
