import sys, os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import json
from pathlib import Path
from datetime import datetime
from typing import Optional, List, Tuple, Dict

from google.generativeai import GenerativeModel, configure
from dotenv import load_dotenv

# ğŸ”§ í™˜ê²½ ë° ëª¨ë¸ ì„¤ì •
load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    raise ValueError("í™˜ê²½ë³€ìˆ˜ GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
configure(api_key=GEMINI_API_KEY)
model = GenerativeModel(model_name="models/gemini-1.5-flash")

class PlanAgent:
    """
    PlanAgent generates blog plans using templates and selects the best candidate.
    - Test mode: ì‚¬ìš©ì ì…ë ¥ X (input data : ìµœê·¼ CLI log ì½ì–´ì™€ ì‚¬ìš©, test_log/cli) -> 2-way í‰ê°€(evaluation) ì§„í–‰
    - CORT mode: ì‚¬ìš©ì ì…ë ¥ O (input_data : ì§ì ‘ CLI ì…ë ¥) â†’ N-way í‰ê°€(evaluation) ì§„í–‰

    Returns:
    - result_dict: Parsed JSON from best_output 
    - candidates: List of all candidate JSON strings
    - evaluation: Dict containing 'selected' index and 'reason' details
    - input_data: The dict used for generation (ìœ„ ë‚´ìš© ì°¸ê³ )
    """
    def __init__(
            self,
            gen_template_path: str = "test_prompt/plan_generation_prompt.txt",
            eval2_template_path: str = "test_prompt/plan_evaluation_prompt.txt",
            nway_template_path: str = "test_prompt/plan_nway_evaluation_prompt.txt",
            default_nway_rounds: int = 3
        ):
            self.gen_template = self._load_template(gen_template_path, "ìƒì„±")
            self.eval2_template = self._load_template(eval2_template_path, "2-way í‰ê°€")
            self.nway_template = self._load_template(nway_template_path, "N-way í‰ê°€")
            self.default_nway_rounds = default_nway_rounds

    def _load_template(self, path: str, name: str) -> str:
        file = Path(path)
        if not file.exists():
            raise FileNotFoundError(f"{name} í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file}")
        return file.read_text(encoding="utf-8")

    def generate(
        self,
        input_data: Optional[dict] = None,
        mode: str = "cli",
        rounds: Optional[int] = None
    ) -> Tuple[Dict, Dict[str, str], Dict, dict]:
        loaded_input = self._prepare_input(input_data, mode)
        if rounds is None:
            rounds = self.default_nway_rounds if input_data is not None else 2

        # ë””ë²„ê¹…ìš© ì¶œë ¥ (plan_agent.pyë§Œ ëŒë¦´ ë•Œ, run_agents.pyë¡œ ëŒë¦´ ë•Œì—ëŠ” ì£¼ì„ ì²˜ë¦¬)
        # print(f"ğŸ” [DEBUG] mode={mode}, rounds={rounds}")
        # print(json.dumps(loaded_input, indent=2, ensure_ascii=False))

        prompt = self._format_prompt(self.gen_template, loaded_input)
        raw_candidates = self._generate_candidates(prompt, rounds)
        # map to labels
        candidates = { f"í›„ë³´ {i+1}": raw_candidates[i] for i in range(len(raw_candidates)) }

        if rounds == 2:
            best_output, selected, reason = self.evaluate_candidates(raw_candidates)
        else:
            best_output, selected, reason = self.evaluate_candidates_nway(raw_candidates)

        result = self._parse_json(best_output, raw_candidates, selected)
        evaluation_info = {"selected": selected, "reason": reason}
        return result, candidates, evaluation_info, loaded_input

    def _prepare_input(self, input_data: Optional[dict], mode: str) -> dict:
        if input_data is not None:
            return input_data
        if mode == "cli":
            logs = sorted(Path("test_logs/cli").glob("*_input_log.json"))
            if not logs:
                raise FileNotFoundError("CLI ì…ë ¥ ë¡œê·¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            with open(logs[-1], "r", encoding="utf-8") as f:
                return json.load(f)
        raise ValueError("ìœ íš¨í•œ ì…ë ¥ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    def _format_prompt(self, template: str, input_data: dict) -> str:
        try:
            return template.format(**input_data)
        except KeyError as e:
            raise ValueError(f"í”„ë¡¬í”„íŠ¸ì— í•„ìš”í•œ í‚¤ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {e}")
        except Exception as e:
            raise ValueError(f"í”„ë¡¬í”„íŠ¸ í¬ë§· ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    def _clean_text(self, text: str) -> str:
        lines = text.splitlines()
        if lines and lines[0].startswith("```"):
            lines = lines[1:]
        if lines and lines[-1].startswith("```"):
            lines = lines[:-1]
        return "\n".join(lines).strip()

    def _generate_candidates(self, prompt: str, rounds: int) -> List[str]:
        candidates: List[str] = []
        for i in range(rounds):
            raw = model.generate_content(prompt).text.strip()
            output = self._clean_text(raw)
            if output:
                candidates.append(output)
            else:
                print(f"âš ï¸ í›„ë³´ {i+1} ë¹ˆ ì‘ë‹µ")
        if len(candidates) < 2:
            raise ValueError(f"í›„ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤: {len(candidates)}")
        return candidates

    def evaluate_candidates(self, candidates: List[str]) -> Tuple[str, str, dict]:
        prompt = self.eval2_template.format(
            candidate_1=candidates[0],
            candidate_2=candidates[1]
        )
        raw = model.generate_content(prompt).text.strip()
        eval_text = self._clean_text(raw)
        eval_result = json.loads(eval_text)
        sel = eval_result.get("selected", "").strip()
        reason = eval_result.get("reason", {})
        return candidates[int(sel[-1]) - 1], sel, reason

    def evaluate_candidates_nway(self, candidates: List[str]) -> Tuple[str, str, dict]:
        # 1) ê° í›„ë³´ë¥¼ ë¸”ë¡ ìŠ¤íŠ¸ë§ìœ¼ë¡œ í•©ì¹˜ê¸°
        blocks = "\n".join(f"í›„ë³´ {i+1}:\n{cand}" for i, cand in enumerate(candidates))
        
        # 2) í¬ë§·ìš© ë”•ì…”ë„ˆë¦¬ ìƒì„±
        format_args = {
            'n': len(candidates),
            'candidates': blocks
        }
        # 3) candidate_1, candidate_2â€¦ í‚¤ ì¶”ê°€
        for idx, cand in enumerate(candidates, start=1):
            format_args[f'candidate_{idx}'] = cand
        
        # 4) í…œí”Œë¦¿ì— í‚¤ì›Œë“œ ì¸ìë¡œ ë„˜ê²¨ì„œ í¬ë§·
        prompt = self.nway_template.format(**format_args)
        
        # 5) í‰ê°€ ìš”ì²­
        raw = model.generate_content(prompt).text.strip()
        eval_text = self._clean_text(raw)
        eval_result = json.loads(eval_text)
        sel = eval_result.get("selected", "").strip()
        reason = eval_result.get("reason", {})
        idx = int(sel.replace("í›„ë³´", "").strip()) - 1
        return candidates[idx], sel, reason

    def _parse_json(self, best_output: str, candidates: List[str], selected: str) -> dict:
        try:
            return json.loads(best_output)
        except json.JSONDecodeError:
            idx = int(selected.replace("í›„ë³´", "").strip()) - 1
            return json.loads(candidates[idx])

    def save_log(
        self,
        input_data: dict,
        candidates: Dict[str, str],
        best_output: str,
        selected: str,
        reason: dict,
        mode: str = "cli"
    ) -> None:
        now = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_dir = Path(f"test_logs/{mode}")
        log_dir.mkdir(parents=True, exist_ok=True)
        with open(log_dir / f"{now}_plan_log.json", "w", encoding="utf-8") as f:
            json.dump({
                "input": input_data,
                "candidates": candidates,
                "selected": selected,
                "best_output": best_output,
                "reason": reason
            }, f, ensure_ascii=False, indent=2)

# âœ… CLI í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    print("ğŸ” PlanAgent CLI í…ŒìŠ¤íŠ¸ ì‹œì‘")
    agent = PlanAgent()
    result, candidates, evaluation_info, input_data = agent.generate(mode="cli")
    agent.save_log(
        input_data=input_data,
        candidates=candidates,
        best_output=json.dumps(result, ensure_ascii=False),
        selected=evaluation_info["selected"],
        reason=evaluation_info["reason"],
        mode="cli"
    )
    print("\nğŸ—‚ï¸ ê²°ê³¼ê°€ test_logs/cli ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    output = {**result, **evaluation_info}
    print(json.dumps(output, ensure_ascii=False, indent=2))

